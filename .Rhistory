(y <- seq(1, 10, length.out = 5))
(z <- seq(1,1000, length.out = 25))
z
library(nycflights13)
library(nycflights13)
library(nycflight13)
library(tidyverse)
library(nycflights13)
library(nycflights)
install.packages(nycflight13)
install.packages(nycflights13)
library("nicyflight13")
install.packages("nycflights13")
library(nycflights13)
library(tidyverse)
flights
view(flights)
filter(flights, month == 1, day ==1)
view(filter(flights, month==1, day==1))
jan1 <- filter(flights, month==1, day==1)
view(jan1)
filter(flights, month =1)
sqrt(2) ^ 2 == 2
1/49 * 49 == 1
near(sqrt(2) ^ 2, 2)
near(1/49 * 49, 1)
filter(flights, month==11 | month==12)
view(filter(flights, month==11 | month==12))
nov_dec <- filter(flights, month %in% c(11, 12))
filter(flights, arr_delay <= 120, dep_delay <= 120)
NA > 5
10 == NA
NA == NA
is.na(x)
df <- tibble(x = c(1, NA, 3))
filter(df, x > 1)
filter(df, is.na(x) | x > 1)
view(flights.head)
flights
view)flights)
view(flights)
filter(flights, origin == IAH | origin == HOU)
filter(flights, origin == "IAH" | origin == "HOU")
houston <-filter(flights, origin == "IAH" | origin == "HOU")
houston <-filter(flights, dest == "IAH" | dest == "HOU")
houston <-filter(flights, origin == "IAH" | dest == "HOU")
houston <-filter(flights, origin == "IAH" | origin == "HOU")
houston <-filter(flights, origin == "IAH" & origin == "HOU")
houston <-filter(flights, origin == c('IAH', 'HOU'))
houston <-filter(flights, origin %in% c('IAH', 'HOU'))
houston <-filter(flights, dept %in% c('IAH', 'HOU'))
houston <-filter(flights, dept %in% c("IAH", "HOU"))
houston <-filter(flights, dest %in% c("IAH", "HOU"))
houston <-filter(flights, origin %in% c("IAH", "HOU"))
houston <-filter(flights, dest %in% c("IAH", "HOU"))
operation <-filter(flights, carrier %in% c("UN"))
flights?
?flights
?flights
airlines
operation <-filter(flights, carrier %in% c("UA"))
operation <-filter(flights, carrier %in% c("UA", "DL", "AA"))
?flights
ggplot(data = operation) +
geom_bar(mapping = aes(x = air_time))
?flights
ggplot(data = operation) +
geom_bar(mapping = aes(x = carrier, y=airt_time))
ggplot(data = operation) +
geom_bar(mapping = aes(x = carrier, y=air_time))
ggplot(data = operation) +
geom_bar(mapping = aes(x = carrier, y=air_time))
ggplot(data = operation) +
geom_bar(mapping = aes(x = carrier))
ggplot(data = operation) +
geom_bar(mapping = aes(x = carrier, y=air_time))
geom_bar(mapping = aes(x = carrier, y=air_time, group=1)
ggplot(data = operation) +
geom_bar(mapping = aes(x = carrier, y=air_time, group=1))
geom_bar(mapping = aes(x = carrier, y=air_time)
operation <-filter(flights, carrier %in% c("UA", "DL", "AA"))
ggplot(data = operation) +
geom_bar(mapping = aes(x = carrier, y=air_time)
ggplot(data = operation) +
geom_bar(mapping = aes(x = carrier, y=air_time)
ggplot(data = operation) +
geom_bar(mapping = aes(x = carrier, y=air_time))
ggplot(data = operation) +
geom_bar(mapping = aes(x = carrier, y=air_time))
ggplot(data = operation) +
geom_bar(mapping = aes(x = carrier, y=air_time)), stat="identity"
ggplot(data = operation) +
geom_bar(mapping = aes(x = carrier, y=air_time)), stat="identity"
ggplot(data = operation) +
geom_bar(mapping = aes(x = carrier, y=air_time), stat="identity")
library(tidyverse)
library(tidytext)    # text mining
library(gutenbergr)  # Project Gutenberg downloadable books.  gutenberg_metadata to view index
library(textdata)
install.packages(tidytext)
install.packages("tidytext")
install.packages("gutenbergr")
install.packages("textdata")
library(tidyverse)
library(tidytext)    # text mining
library(gutenbergr)  # Project Gutenberg downloadable books.  gutenberg_metadata to view index
library(textdata)
#-----------------------------
rm(list = ls())
get_sentiments("bing")
get_sentiments("afinn")
View(gutenberg_metadata)
twain_books <- gutenberg_metadata %>%
filter(author == "Twain, Mark", has_text == TRUE) %>%
select(gutenberg_id, author, title)
View(twain_books)
gutenberg_metadata %>%
filter(gutenberg_id %in% c(74, 76, 86, 245, 1837, 3177)) %>%
select(gutenberg_id, title, author)
twain_book_data <- gutenberg_download(c(74, 76, 86, 245, 1837, 3177))
saveRDS(twain_book_data, "C:/Data/R/twain_book_data.rds")
twain_book_data <- readRDS("C:/Data/R/twain_book_data.rds")
select(gutenberg_id, title, author)
filter(gutenberg_id %in% c(74, 76, 86, 245, 1837, 3177)) %>%
select(gutenberg_id, title, author)
twain_books <- gutenberg_metadata %>%
filter(author == "Twain, Mark", has_text == TRUE) %>%
select(gutenberg_id, author, title)
gutenberg_metadata %>%
filter(gutenberg_id %in% c(74, 76, 86, 245, 1837, 3177)) %>%
select(gutenberg_id, title, author)
twain_book_data <- gutenberg_download(c(74, 76, 86, 245, 1837, 3177))
saveRDS(twain_book_data, "C:/Data/R/twain_book_data.rds")
twain_book_data <- readRDS("C:/Data/R/twain_book_data.rds")
saveRDS(twain_book_data, "C:/Data/R/twain_book_data.rds")
twain_books <- gutenberg_metadata %>%
filter(author == "Twain, Mark", has_text == TRUE) %>%
select(gutenberg_id, author, title)
gutenberg_metadata %>%
filter(gutenberg_id %in% c(74, 76, 86, 245, 1837, 3177)) %>%
select(gutenberg_id, title, author)
twain_book_data <- gutenberg_download(c(74, 76, 86, 245, 1837, 3177))
saveRDS(twain_book_data, "C:/Data/R/twain_book_data.rds")
head(twain_book_data, 15)
twain_book_data <- twain_book_data %>%
group_by(gutenberg_id) %>%
mutate(linenum = row_number())
view(twain_book_data)
# tokenize to one word per row (tidytext package)
twain_tokens <- twain_book_data %>%
unnest_tokens(word, text)    # by word, colname = "text"
twain_tokens <- twain_book_data %>%
unnest_tokens(word, text)    # by word, colname = "text"
view(twain_tokens)
#----- Get Twain sentiments and graph net sentiment over time -----
# inner_join sentiment to score each word
# create index for every 80 lines, spread to + & - cols and get net sentiment
twain_tokens %>%
inner_join(get_sentiments("bing"), by = "word")
twain_tokens %>%
inner_join(get_sentiments("bing"), by = "word")
twain_tokens %>%
inner_join(get_sentiments("bing"), by = "word") %>%
count(gutenberg_id, index = linenum %/% 80, sentiment)
twain_tokens %>%
inner_join(get_sentiments("bing"), by = "word") %>%
count(gutenberg_id, index = linenum %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0)
twain_tokens %>%
inner_join(get_sentiments("bing"), by = "word") %>%
count(gutenberg_id, index = linenum %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(net_sentiment = positive - negative)
twain_tokens %>%
inner_join(get_sentiments("bing"), by = "word") %>%
count(gutenberg_id, index = linenum %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(net_sentiment = positive - negative) %>%
inner_join(twain_books, by = "gutenberg_id")
# Do all the things and assign to twain_sentiment_by_index
twain_sentiment_by_index <- twain_tokens %>%
inner_join(get_sentiments("bing"), by = "word") %>%
count(gutenberg_id, index = linenum %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(net_sentiment = positive - negative) %>%
inner_join(twain_books, by = "gutenberg_id")
library(ggplot2)
ggplot(twain_sentiment_by_index, aes(x = index, y = net_sentiment, fill = title)) +
geom_col(show.legend = FALSE) +
facet_wrap(~title, ncol = 2, scales = "free_x") +
labs(title = "Net Sentiment Over Time", x = "1X = 80 lines of text", y = "Net Sentiment")
top_10_each_book <- twain_tokens %>%
inner_join(get_sentiments("bing"), by = "word") %>%
group_by(gutenberg_id, word) %>%
count(word, sentiment) %>%
arrange(gutenberg_id, desc(n)) %>%
group_by(gutenberg_id) %>%
top_n(10)
top_10_each_book
data("co2")
pairs(data)
pairs(co2)
data(trees)
pairs(trees)
data(co2)
pairs(co2)
data(BJsales)
data
pairs(BJsales)
trees
BJsales
co2
data(cars)
pairs(cars)
setwd("D:/Documents/Vanderbilt Data Analytics/Homework/Final Project")
library(GGally)
data <- read.csv("CSVs/heart.csv")
ggpairs(data)
dev.off()
dev.off()
ggsave("correlations.pdf")
